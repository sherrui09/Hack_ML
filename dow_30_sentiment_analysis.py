# -*- coding: utf-8 -*-
"""DOW_30_Sentiment_Analysis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UXUMdrTYpd--RwoI_CqVArZF4bstFQao
"""

tkr = 'AAPL' ## user input

pip install intrinio_sdk

import time
import intrinio_sdk
import pandas as pd
import nltk
from nltk.sentiment.vader import SentimentIntensityAnalyzer

from intrinio_sdk.rest import ApiException
from pprint import pprint

   
intrinio_sdk.ApiClient().configuration.api_key['api_key'] = 'OmM0NGJmYTM4YjQ5ZTYwOThmMjFmOTA3MWI1MTBmYjlj'

company_api = intrinio_sdk.CompanyApi()
PAGE_SIZE = 500
next_page = ''

def getDictionaryFromXLSFile(XLSFile, ratings):
    wordlist = {}
    for i in range(1,8):
        frame = XLSFile.parse(XLSFile.sheet_names[i], header=None)
        frame.columns = ['word']
        frame['score'] = ratings[i - 1]
        dict =frame.set_index('word').to_dict()
        wordlist = {**wordlist, **dict}
    return wordlist

def updateLexicon(sia):
    #import CSV
    file_path = 'LoughranMcDonald_SentimentWordLists_2018.xlsx'
    file = pd.ExcelFile(file_path)

    wordlist = getDictionaryFromXLSFile(file, [-1,1,-1,-1,1,-1,-1])
    
    sia.lexicon.update(wordlist)

nltk.download('vader_lexicon')
sia = SentimentIntensityAnalyzer()

pip install --upgrade xlrd

pip install --upgrade pandas

updateLexicon(sia)

def inPassage(passage, list): 
    for word in list:
        if word in passage:
            return True 
    return False

def createColumn(df, columnName, list):
    df[columnName] = df['summary'].apply(inPassage, args=(list,))

eWords = {'environment', 'climate', 'sustainable', 'sustainability', 'green', 'planet'}
sWords = {'social','community', 'responsibility', 'philanthropy', 'charity'}
gWords = {'governance', 'board', 'administration', 'organization', 'conduct', 'diversity'}

def getSentimentScore(passage):
    try:
        score = sia.polarity_scores(str(passage))['compound']
    except TypeError:
        score = 0
    return score

def getESGscore(ticker):
    try:
        api_response = company_api.get_company_news(ticker, page_size=PAGE_SIZE, next_page=next_page)
    except ApiException as e:
        print("Exception when calling CompanyApi->get_company_news: %s\r\n" % e)
    
    df = pd.DataFrame(api_response.news_dict)
    del df['id']
    
    createColumn(df, 'eContent', eWords)
    createColumn(df, 'sContent', sWords)
    createColumn(df, 'gContent', gWords)
    
    df['sentiment'] = df.summary.apply(getSentimentScore)
    
    eScore = df[df['eContent'] == True].sum()['sentiment'] / PAGE_SIZE
    sScore = df[df['sContent'] == True].sum()['sentiment'] / PAGE_SIZE
    gScore = df[df['gContent'] == True].sum()['sentiment'] / PAGE_SIZE
    
    return [eScore, sScore, gScore]

scores = getESGscore(tkr)
print("Environment: {0} Social: {1} Governance: {2}".format(scores[0], scores[1], scores[2]))

esgData = pd.DataFrame(index = [tkr], columns=['eScore', 'sScore','gScore'])

esgData['eScore'].loc[tkr] = scores[0]
esgData['sScore'].loc[tkr] = scores[1]
esgData['gScore'].loc[tkr] = scores[2]

esgData.plot(kind='bar')